# 22 DSA Patterns to Master

Mastering these 22 DSA patterns will help you tackle a wide range of coding problems and improve your problem-solving skills.

---

## 1. Fast and Slow Pointer

- **Cycle detection method**
- **O(1) space efficiency**
- Used in **linked list problems** to detect cycles

---

## 2. Merge Intervals

- **Sort and merge intervals**
- **O(n log n)** time complexity
- Efficient handling of **overlapping intervals**

---

## 3. Sliding Window

- **Fixed/variable window size**
- **O(n)** time optimization
- Used in **subarray/substring problems**

---

## 4. Islands (Matrix Traversal)

- **DFS/BFS traversal**
- Detects **connected components** in a grid
- Commonly used in **2D grid problems** like finding islands

---

## 5. Two Pointers

- **Dual pointer strategy**
- **O(n)** linear time complexity
- Applied in **array/list problems** (e.g., two sum, partitioning)

---

## 6. Cyclic Sort

- **Sorting in cycles**
- **O(n)** time complexity
- **Constant space usage**
- Efficient sorting technique for **range-limited numbers**

---

## 7. In-place Reversal of Linked List

- **Reverse a list without extra space**
- **O(n)** time efficiency
- Uses **pointer manipulation** technique

---

## 8. Breadth First Search (BFS)

- **Level-by-level traversal**
- Utilizes a **queue** structure
- Often used in **shortest path problems**

---

## 9. Depth First Search (DFS)

- **Recursive/backtracking approach**
- Utilizes a **stack** (or recursion)
- Applied in **tree/graph traversal** problems

---

## 10. Two Heaps

- **Max and min heaps**
- Efficient for **median tracking**
- **O(log n)** time complexity for insertions

---

## 11. Subsets

- **Generate all subsets**
- Can be solved using **recursion or iteration**
- Implemented with **backtracking or bitmasking**

---

## 12. Modified Binary Search

- Variants of **binary search** for **rotated** or **specialized arrays**
- **O(log n)** time complexity

---

## 13. Bitwise XOR

- **Toggle bits operation**
- **O(1)** space complexity
- Efficient for **pairing problems**

---

## 14. Top 'K' Elements

- Use of **heap** or **quickselect** to efficiently find the top k elements
- **O(n log k)** time complexity
- Effective for **selection problems**

---

## 15. K-way Merge

- **Merge sorted lists** efficiently
- Uses a **min-heap** for merging
- **O(n log k)** time complexity

---

## 16. 0/1 Knapsack (Dynamic Programming)

- Solve the **knapsack problem** by choosing or skipping items
- **O(n * W)** time complexity
- Maximizes value selection

---

## 17. Unbounded Knapsack (Dynamic Programming)

- Deals with **unlimited item choices**
- **O(n * W)** time complexity
- Allows **multiple item selection**

---

## 18. Topological Sort (Graphs)

- Sorts **directed acyclic graphs (DAGs)**
- Resolves **order dependencies**
- Uses **DFS or BFS** for solving

---

## 19. Monotonic Stack

- Maintains a **monotonic increasing or decreasing stack**
- Optimized for **range queries**
- **O(n)** time complexity

---

## 20. Backtracking

- **Recursive decision-making**
- Explores all possible solutions
- Uses **pruning** to optimize by cutting off invalid paths

---

## 21. Union Find (Disjoint Set)

- Tracks and **merges connected components**
- Utilized for **network connectivity** or **disjoint set operations**

---

## 22. Greedy Algorithm

- **Locally optimal choices** at each step
- Efficient for problems with **optimal substructure**
- Commonly used for tasks like **activity selection**, **minimum coin change**

---

## 23. Hashing Algorithm

- **Frequency Counting:** Use hash maps to count occurrences (e.g., finding the first unique character).
- **Existence Check:** Use hash maps for fast lookup and checking if a value exists (e.g., finding pairs that sum to a target).
- **Grouping:** Use hash maps to group data based on a key (e.g., grouping anagrams).
- Substring Search: Use rolling hash or other hashing techniques for efficient string matching.
- Collision Handling: Understand how hash tables handle collisions through separate chaining or open addressing (internal hash table mechanics).
- **One Pass solution:** The algorithm makes a single traversal or iteration over the data to achieve the result. (e.g **Two sum** & **Isomorphic Strings**).
- **two-pass solution:** The algorithm makes exactly two independent traversals over the data. (e.g Set Mismatch)
- **O(n) Spaced Complexity Approach**

---
